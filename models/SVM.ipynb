{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# algorithms\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used cu121 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I load all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "genre_names = ['rock', 'pop', 'arabesk', 'turk_sanat', 'jazz', 'rap']\n",
    "\n",
    "# Load the features.pkl file\n",
    "with open('../data/features.pkl', 'rb') as file:\n",
    "    all_features = pickle.load(file)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_features)\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stft_db', 'spectral_rolloff', 'zcr', 'chroma', 'mfccs', 'rms', 'spectral_centroid', 'file_name', 'label']\n",
      "0      [[0.06005859375, 0.0927734375, 0.11376953125, ...\n",
      "1      [[0.046875, 0.07421875, 0.10009765625, 0.10742...\n",
      "2      [[0.03564453125, 0.060546875, 0.08349609375, 0...\n",
      "3      [[0.076171875, 0.11865234375, 0.15478515625, 0...\n",
      "4      [[0.02685546875, 0.0419921875, 0.06396484375, ...\n",
      "                             ...                        \n",
      "632    [[0.10693359375, 0.16162109375, 0.22216796875,...\n",
      "633    [[0.0048828125, 0.00634765625, 0.00732421875, ...\n",
      "634    [[0.025390625, 0.03369140625, 0.03564453125, 0...\n",
      "635    [[0.01953125, 0.0234375, 0.03564453125, 0.0683...\n",
      "636    [[0.0751953125, 0.099609375, 0.109375, 0.07958...\n",
      "Name: zcr, Length: 637, dtype: object\n"
     ]
    }
   ],
   "source": [
    "column_names = list(df.columns)\n",
    "print(column_names)\n",
    "print(df['zcr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting labels and x. I used only the 1D datas which are 4 lists: spectral_rolloff, zcr, rms, spectral_centroid. I combined them into a 1280x4 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first element in column: 1\n",
      "Length of first element in column: 1\n",
      "Length of first element in column: 1\n",
      "(637, 5120)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def flatten_column(column):\n",
    "    # Check the length of the first few elements to ensure they are 1280\n",
    "    print(f\"Length of first element in column: {len(column.iloc[0])}\")\n",
    "    return column.apply(lambda x: np.array(x[0]).reshape(-1))\n",
    "\n",
    "\n",
    "# Flatten the lists in each feature column by averaging the values in the list\n",
    "df['zcr'] = flatten_column(df['zcr'])\n",
    "df['rms'] = flatten_column(df['rms'])\n",
    "df['spectral_centroid'] = flatten_column(df['spectral_centroid'])\n",
    "\n",
    "data = df[['spectral_rolloff', 'zcr', 'rms', 'spectral_centroid']]\n",
    "\n",
    "# Flatten each row (concatenate the arrays in each row into a single feature vector)\n",
    "# Function to flatten each row by concatenating all lists in the row\n",
    "def flatten_row(row):\n",
    "    # Concatenate all 4 lists into a single array\n",
    "    return np.concatenate([np.array(row[col]).reshape(-1) for col in row.index])\n",
    "\n",
    "# Apply the flattening function to each row\n",
    "data = np.array(data.apply(lambda row: flatten_row(row), axis=1).tolist())\n",
    "\n",
    "y = df['label'].values\n",
    "\n",
    "# Output the shape of the flattened data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637, 5120)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transforming and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data using the scaler\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM train time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.05% for parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 31.44% for parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 43.62% for parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 50.69% for parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "Accuracy: 31.44% for parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 43.81% for parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 50.88% for parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 43.23% for parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 64.63% for parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 52.44% for parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "Accuracy: 43.23% for parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 64.63% for parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 52.44% for parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 46.38% for parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 65.22% for parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 42.82% for parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "Accuracy: 46.38% for parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 65.22% for parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 42.43% for parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 47.36% for parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 65.22% for parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 45.18% for parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 53.05% for parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "Accuracy: 47.36% for parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 65.22% for parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 45.38% for parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy on test set with best model: 63.28%\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search Cross Validation\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Prepare the data for storing results\n",
    "accuracy_results = []\n",
    "\n",
    "# Print accuracy for each parameter combination\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(f\"Accuracy: {mean_score * 100:.2f}% for parameters: {params}\")\n",
    "    accuracy_results.append({\n",
    "        'Parameters': str(params),  # Convert dictionary to string\n",
    "        'Accuracy (%)': mean_score * 100  # Store accuracy for each combination\n",
    "    })\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "\n",
    "# Train the best model on the full training set\n",
    "svm_classifier_best = grid_search.best_estimator_\n",
    "\n",
    "# Predict with the best model on the test set\n",
    "y_pred_best = svm_classifier_best.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Accuracy on test set with best model: {accuracy_best * 100:.2f}%\")\n",
    "\n",
    "# Append the best model results at the end\n",
    "accuracy_results.append({\n",
    "    'Parameters': str(best_params),  # Best Parameters as a string\n",
    "    'Accuracy (%)': accuracy_best * 100  # Accuracy for the best model\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV results saved to 'grid_search_best_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(accuracy_results)\n",
    "\n",
    "# Save the results to CSV\n",
    "results_df.to_csv('results/svm.csv', index=False)\n",
    "\n",
    "print(\"GridSearchCV results saved to 'grid_search_best_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
